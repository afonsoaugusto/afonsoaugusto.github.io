---
layout: post
title: "Domain 3: Applications of Foundation Models (Standard AIF)"
date: 2025-04-07 00:00:00 +0000
categories: article
---

## Domain 3 Introduction

O texto apresenta o **Domínio 3**, que aborda a **aplicação de modelos de fundação (foundation models)**. Ele se conecta ao Domínio 2, que discutiu os modelos de fundação e seu ciclo de vida, reforçando que são modelos pré-treinados, prontos para uso e treinados em vastos conjuntos de dados.

**Pontos chave do texto:**

* **O que são modelos de fundação:** Grandes redes neurais de aprendizado profundo que servem como ponto de partida para desenvolver modelos de machine learning mais rápidos e baratos para novas aplicações.
* **Diferenciais dos modelos de fundação:**
    * **Adaptabilidade:** Capacidade de realizar diversas tarefas com alta precisão a partir de prompts de entrada (exemplos: NLP, question answering, classificação de imagens).
    * **Tamanho e propósito geral:** Diferentemente dos modelos tradicionais de ML, que são específicos para tarefas como análise de sentimento, classificação de imagens e previsão de tendências.
* **Aplicações dos modelos de fundação:** Suporte ao cliente, tradução de idiomas, geração de conteúdo, geração de código, copywriting, classificação de imagens, criação e edição de imagens de alta resolução, geração de vídeo e áudio, extração de documentos, saúde, veículos autônomos e robótica.
* **Estrutura do Domínio 3:** Dividido em quatro tarefas (task statements) que serão discutidas em lições futuras:
    * **Tarefa 3.1:** Descrever considerações de design para aplicações que usam modelos de fundação (escolha do modelo pré-treinado, efeito dos parâmetros de inferência, RAG e suas aplicações, custos de personalização, serviços AWS para embeddings, papel dos agentes).
    * **Tarefa 3.2:** Escolher técnicas eficazes de prompt engineering (melhores práticas, técnicas, riscos, limitações, conceitos e constructos).
    * **Tarefa 3.3:** Descrever o processo de treinamento e fine-tuning de modelos de fundação (elementos e métodos de treinamento, preparação de dados para fine-tuning).
    * **Tarefa 3.4:** Descrever métodos para avaliar o desempenho de modelos de fundação (abordagens, métricas, como determinar se o modelo atende aos objetivos de negócios).
* **Próximos passos:** Os próximos vídeos abordarão cada uma das quatro tarefas individualmente, preparando o público para um exame sobre o tema. A próxima lição focará na Tarefa 3.1.

Em resumo, o texto serve como uma introdução ao Domínio 3 sobre a aplicação de modelos de fundação, destacando suas características, aplicações e a estrutura dos tópicos que serão abordados nas próximas lições. O objetivo é preparar o leitor para entender os aspectos práticos da utilização desses modelos em diferentes cenários.

### Resumo Detalhado em Tópicos: Modelos de Fundação

**1. O que são modelos de fundação:**

*   **Definição:** Modelos pré-treinados que estão prontos para serem utilizados.
*   **Treinamento:** São treinados em conjuntos de dados massivos (grandes volumes de informações).
*   **Arquitetura:** Geralmente são redes neurais profundas (deep learning) de grande escala.
*   **Propósito:** Fornecem um ponto de partida robusto para o desenvolvimento de modelos de machine learning.
*   **Benefícios:**
    *   Aceleram o desenvolvimento de novas aplicações de machine learning.
    *   Tornam o desenvolvimento mais eficiente em termos de custo.

**2. Diferenciais dos modelos de fundação:**

*   **Adaptabilidade:**
    *   Capacidade de executar uma ampla variedade de tarefas.
    *   Alto grau de precisão na execução dessas tarefas.
    *   Funcionamento baseado em prompts de entrada (instruções ou exemplos fornecidos ao modelo).
    *   Exemplos de tarefas:
        *   Processamento de linguagem natural (NLP).
        *   Respostas a perguntas (question answering).
        *   Classificação de imagens.
*   **Tamanho e Propósito Geral:**
    *   **Tamanho:** São modelos grandes, com um grande número de parâmetros e camadas.
    *   **Propósito Geral:** Não são projetados para uma única tarefa específica, mas para aprender representações gerais dos dados.
    *   **Contraste com modelos tradicionais de Machine Learning:**
        *   **Modelos Tradicionais:** Focados em tarefas específicas.
        *   **Exemplos de tarefas específicas de modelos tradicionais:**
            *   Análise de texto para identificar sentimento (positivo, negativo, neutro).
            *   Classificação de imagens em categorias predefinidas (ex: gatos vs. cachorros).
            *   Previsão de tendências (ex: vendas futuras).
        *   **Modelos de Fundação:** Podem ser adaptados para realizar essas e muitas outras tarefas através de técnicas como prompt engineering ou fine-tuning.

**3. Aplicações dos modelos de fundação:**

*   **Suporte ao Cliente:**
    *   Chatbots avançados capazes de entender e responder a perguntas complexas.
    *   Automatização de tarefas de suporte.
    *   Geração de respostas personalizadas.
*   **Tradução de Idiomas:**
    *   Tradução automática de textos e áudios com alta qualidade e nuances.
*   **Geração de Conteúdo:**
    *   Criação de textos, artigos, roteiros, e-mails, posts para redes sociais, etc.
*   **Geração de Código:**
    *   Auxílio a programadores na escrita de código em diversas linguagens.
    *   Geração automática de trechos de código.
*   **Copywriting:**
    *   Criação de textos persuasivos para marketing e publicidade.
    *   Geração de slogans e títulos criativos.
*   **Classificação de Imagens:**
    *   Identificação de objetos, pessoas, cenas e atividades em imagens.
    *   Categorização automática de grandes volumes de imagens.
*   **Criação e Edição de Imagens de Alta Resolução:**
    *   Geração de imagens fotorrealistas a partir de descrições textuais.
    *   Edição avançada de imagens, como preenchimento de áreas faltantes ou remoção de objetos.
*   **Geração de Vídeo e Áudio:**
    *   Criação de vídeos curtos e animações a partir de texto ou imagens.
    *   Geração de áudio com vozes sintéticas realistas ou música.
*   **Extração de Documentos:**
    *   Identificação e extração de informações relevantes de documentos não estruturados (ex: PDFs, contratos).
    *   Automatização do processamento de documentos.
*   **Saúde:**
    *   Auxílio no diagnóstico de doenças a partir de imagens médicas.
    *   Descoberta de novos medicamentos.
    *   Personalização de tratamentos.
*   **Veículos Autônomos:**
    *   Processamento de dados sensoriais para percepção do ambiente.
    *   Tomada de decisões para navegação segura.
*   **Robótica:**
    *   Permitir que robôs entendam comandos de linguagem natural.
    *   Facilitar a interação entre humanos e robôs.
    *   Melhorar a capacidade de aprendizado e adaptação dos robôs.

## Task Statement 3.1 Lesson 1

O texto apresentado é uma introdução à discussão sobre os critérios de design para aplicações que utilizam *foundation models* (modelos de fundação). O objetivo principal desta primeira parte é identificar e explicar algumas considerações cruciais para a seleção desses modelos pré-treinados.

**Os principais pontos abordados no texto são:**

*   **Contextualização:** O texto se situa dentro do Domínio 3 (tarefa 1) e retoma discussões do Domínio 2 sobre as vantagens e considerações dos modelos pré-treinados (serem grandes e exigirem muitos recursos computacionais).
*   **Objetivo da Tarefa:** Identificar critérios de seleção de modelos pré-treinados, com foco inicial em custo, modalidade e latência. Outros critérios como tamanho, complexidade, customização e comprimentos de entrada/saída são mencionados como parte da lista a ser considerada.
*   **Custo:** A duração e o custo do treinamento são fatores importantes devido aos gastos com hardware e armazenamento. É levantada a questão do equilíbrio entre acurácia e custo de treinamento, enfatizando que a escolha depende dos requisitos do projeto e da necessidade de arquitetar uma solução escalável e eficiente.
*   **Latência:** A velocidade de inferência e os requisitos de tempo real são cruciais, especialmente para aplicações que precisam fornecer resultados instantaneamente. Modelos mais complexos podem ter tempos de inferência mais longos, tornando-os inadequados para certos cenários. O exemplo de um veículo autônomo ilustra a importância da inferência rápida.
*   **Modalidades:** A escolha de modelos que suportam as modalidades de dados necessárias para a aplicação é fundamental. Métodos de ensemble podem combinar modelos de diferentes modalidades para melhorar o desempenho. A necessidade de modelos multilinguais treinados em línguas relevantes também é mencionada.
*   **Outras Considerações (introduzidas):** O texto também introduz brevemente outras considerações importantes como:
    *   **Arquitetura e Complexidade:** Diferentes arquiteturas (CNNs para visão computacional, RNNs para NLP) têm diferentes pontos fortes e fracos. A complexidade do modelo (número de parâmetros, camadas) afeta velocidade, memória e acurácia.
    *   **Performance e Métricas:** Avaliar o desempenho do modelo em datasets originais e novos usando métricas como acurácia, precisão, recall, F1 score, RMSE, MAP e MAE. A importância de escolher métricas relevantes para a tarefa específica (exemplo do MAP para detecção de objetos) e considerar datasets desbalanceados é ressaltada.

**Em resumo, o texto estabelece a base para uma discussão mais aprofundada sobre como selecionar modelos de fundação adequados para diferentes aplicações, enfatizando a necessidade de equilibrar diversos fatores como custo, desempenho, velocidade e os requisitos específicos do caso de uso.** A estrutura do texto indica que as próximas lições continuarão a explorar esses e outros critérios de seleção.

## Task Statement 3.1 Lesson 2

### 1

O texto aborda diversas considerações importantes ao se trabalhar com modelos pré-treinados em aprendizado de máquina, especificamente no contexto da tarefa 3.1 (mencionada no início e no final). As principais ideias e pontos levantados são:

**1. Viéses nos Dados de Treinamento:**
   - É crucial entender e mitigar os riscos e preocupações éticas relacionados a possíveis viéses presentes nos dados utilizados para treinar o modelo pré-treinado.
   - Isso influencia a escolha e o ajuste fino do modelo.

**2. Disponibilidade e Compatibilidade do Modelo Pré-Treinado:**
   - Existem diversas fontes online (TensorFlow Hub, PyTorch Hub, Hugging Face, etc.) para encontrar modelos pré-treinados.
   - É fundamental verificar a compatibilidade do modelo com o framework, linguagem e ambiente de trabalho.
   - Outros aspectos importantes são a licença, a documentação, a regularidade das atualizações e manutenções, e a existência de problemas ou limitações conhecidas.

**3. Customização e Explicabilidade do Modelo Pré-Treinado:**
   - A capacidade de modificar ou estender o modelo pré-treinado para atender às necessidades específicas da tarefa (adição de camadas, classes, features) é uma consideração relevante.
   - Compreender como o modelo funciona e toma decisões é importante. Modelos flexíveis, modulares e transparentes, que ofereçam ferramentas de visualização e interpretação, são desejáveis.

**4. Interpretabilidade vs. Explicabilidade:**
   - **Interpretabilidade:** Refere-se à capacidade de explicar matematicamente, através de coeficientes e fórmulas, o porquê de uma previsão. Isso geralmente é possível em modelos mais simples.
   - **Explicabilidade:** Busca explicar o funcionamento de modelos complexos (como os "foundation models" ou "caixas pretas") através de aproximações locais com modelos mais simples e interpretáveis.
   - **Modelos pré-treinados complexos não são inerentemente interpretáveis** devido à sua natureza. Se a interpretabilidade é um requisito fundamental, modelos mais simples (regressão linear, árvores de decisão) podem ser mais adequados.

**5. Complexidade do Modelo:**
   - Modelos mais complexos podem identificar padrões intrincados nos dados e potencialmente oferecer melhor desempenho.
   - No entanto, maior complexidade acarreta desafios como aumento de custos (computacionais?), dificuldade na explicação das saídas e maiores dificuldades de manutenção.

**6. Outras Considerações (mencionadas brevemente):**
   - Restrições de hardware.
   - Atualizações de manutenção.
   - Privacidade de dados.
   - Transfer learning.

**Em resumo, o texto enfatiza a necessidade de uma avaliação abrangente ao escolher e utilizar modelos pré-treinados, indo além da simples disponibilidade e considerando aspectos cruciais como viéses, compatibilidade, capacidade de customização e, principalmente, a distinção entre interpretabilidade e explicabilidade, além dos impactos da complexidade do modelo.** O autor informa que a discussão sobre a tarefa 3.1 continuará na próxima lição.

### 2

**Resumo para Revisão e Estudo:**

**Tópico:** Considerações Adicionais no Uso de Modelos Pré-Treinados

**Pontos Chave:**

*   **Vieses nos Dados de Treinamento:**
    *   Importância de mitigar riscos e abordar questões éticas.
    *   Necessidade de decisões informadas sobre seleção e ajuste fino.
*   **Disponibilidade e Compatibilidade do Modelo:**
    *   Diversas fontes online (TensorFlow Hub, PyTorch Hub, Hugging Face).
    *   Verificar compatibilidade com framework, linguagem e ambiente.
    *   Checar licença, documentação, atualizações, manutenção e limitações conhecidas.
*   **Customização e Explicabilidade:**
    *   Possibilidade de modificar/estender o modelo (adição de camadas, classes, features).
    *   Importância de entender o funcionamento e as decisões do modelo.
    *   Buscar modelos flexíveis, modulares, transparentes e com ferramentas de visualização/interpretação.
*   **Interpretabilidade vs. Explicabilidade:**
    *   **Interpretabilidade:** Capacidade de explicar matematicamente as previsões (comum em modelos simples). Modelos complexos (como foundation models) não são inherentemente interpretáveis ("caixa preta").
    *   **Explicabilidade:** Tenta explicar a "caixa preta" aproximando-a localmente com um modelo mais simples e interpretável.
    *   Modelos pré-treinados não são transparentes por design. Se interpretabilidade for crucial, modelos mais simples podem ser preferíveis (ex: regressão linear, árvores de decisão).
*   **Complexidade do Modelo:**
    *   Modelos complexos podem identificar padrões intrincados, mas dificultam manutenção e interpretabilidade.
    *   Maior complexidade pode melhorar o desempenho, mas aumentar custos e dificultar a explicação dos resultados.
*   **Outras Considerações (mencionadas):** Restrições de hardware, atualizações de manutenção, privacidade de dados, aprendizado por transferência, etc.

**Próximo Passo:** Continuação do tópico 3.1 na próxima aula.

## Task Statement 3.1 Lesson 3

O texto aborda o tema da **inferência em modelos de fundação**, com foco em como os **parâmetros de inferência** e os **prompts** influenciam as respostas do modelo. Ele também introduz o conceito de **Retrieval Augmented Generation (RAG)** e a importância de **bancos de dados vetoriais** nesse processo.

Aqui estão os principais pontos do texto:

*   **Inferência:** Definida como o processo de usar um modelo treinado para fazer previsões em novos dados. Em modelos de linguagem, isso significa gerar uma saída (resposta) a partir de uma entrada (prompt).
*   **Amazon Bedrock:** Mencionado como uma plataforma que permite executar inferência em diversos modelos de fundação, oferecendo a flexibilidade de usar modelos base, customizados ou provisionados.
*   **Inputs para Inferência:** O principal input fornecido a um modelo durante a inferência é o **prompt**.
*   **Parâmetros de Inferência:** São valores ajustáveis que controlam e influenciam a resposta do modelo. O texto lista exemplos como:
    *   **Randomness e Diversidade:** Temperatura, Top K, Top P.
    *   **Comprimento da Resposta:** Response length, penalties, stop sequences.
*   **Importância da Experimentação:** É crucial experimentar com diferentes prompts e parâmetros de inferência para encontrar o equilíbrio ideal entre diversidade, coerência e eficiência de recursos. Além disso, é necessário monitorar e ajustar esses parâmetros em produção.
*   **Prompts:** Definidos como um conjunto específico de entradas fornecidas pelo usuário para guiar o LLM a gerar uma resposta apropriada. Prompts podem ser enriquecidos com dados contextuais de bancos de dados internos.
*   **Retrieval Augmented Generation (RAG):** Uma técnica que envolve integrar dados externos (de bancos de dados, especialmente bancos de dados vetoriais) ao prompt para enriquecer semanticamente a entrada e melhorar a qualidade e relevância da resposta gerada pelo modelo.
*   **Bancos de Dados Vetoriais:** São coleções de dados armazenados como representações matemáticas (vetores). Eles armazenam dados estruturados e não estruturados juntamente com seus vetores de embedding.
*   **Vector Embeddings:** Representações numéricas de dados (como palavras e frases) que capturam seu significado e relações semânticas. Um modelo de machine learning (especialmente um modelo de embedding) é necessário para criar esses vetores.
*   **Relação entre Modelos de ML e Bancos de Dados Vetoriais:** Um modelo de machine learning é um pré-requisito para criar um banco de dados vetorial, pois é usado para gerar os embeddings. Bancos de dados vetoriais servem como referência factual para aplicações baseadas em modelos de fundação, ajudando a recuperar dados confiáveis.
*   **Vantagens dos Bancos de Dados Vetoriais:** Permitem buscas eficientes e rápidas, além de oferecer funcionalidades como gerenciamento de dados, tolerância a falhas, autenticação, controle de acesso e um motor de consulta.
*   **Knowledge Bases no Amazon Bedrock:** Um exemplo de como coletar fontes de dados em um repositório para aproveitar o RAG.
*   **Tradeoffs de Custo:** O texto enfatiza a importância de entender os tradeoffs de custo das diferentes abordagens para personalização de modelos de fundação (pré-treinamento, fine-tuning, aprendizado in-context e RAG) para o exame.

Em resumo, o texto estabelece as bases para entender como interagir com modelos de fundação através da inferência, destacando o papel crucial dos parâmetros e prompts. Ele também introduz o conceito avançado de RAG e a infraestrutura subjacente dos bancos de dados vetoriais, enfatizando a importância de considerar diferentes abordagens e seus respectivos custos. A próxima lição se aprofundará no RAG.

## Links

1 - What Are Foundation Models?
<https://aws.amazon.com/what-is/foundation-models/>

2 - Inference Parameters
<https://docs.aws.amazon.com/bedrock/latest/userguide/inference-parameters.html>

3 - Knowledge Bases for Amazon Bedrock
<https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html>

4 - Agents for Amazon Bedrock
<https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html>

5 - Amazon OpenSearch Service’s Vector Database Capabilities Explained
<https://aws.amazon.com/blogs/big-data/amazon-opensearch-services-vector-database-capabilities-explained/>

6 - The Role of Vector Datastores in Generative AI Applications
<https://aws.amazon.com/blogs/database/the-role-of-vector-datastores-in-generative-ai-applications/>

7 - Vector Engine for Amazon OpenSearch Serverless
<https://aws.amazon.com/opensearch-service/serverless-vector-engine/>

8 - What Is Prompt Engineering?
<https://aws.amazon.com/what-is/prompt-engineering/>

9 - Domain-Adaptation Fine-Tuning of Foundation Models in Amazon SageMaker JumpStart on Financial Data
<https://aws.amazon.com/blogs/machine-learning/domain-adaptation-fine-tuning-of-foundation-models-in-amazon-sagemaker-jumpstart-on-financial-data/>

10 - Metric: bleu
<https://huggingface.co/spaces/evaluate-metric/bleu>

11 - Metric: rouge
<https://huggingface.co/spaces/evaluate-metric/rouge>

12 - ReFT: Representation Fine-Tuning for Language Models
<https://huggingface.co/papers/2404.03592>